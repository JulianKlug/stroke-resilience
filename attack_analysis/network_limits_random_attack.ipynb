{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import multitest\n",
    "from multipy.fdr import qvalue\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Limits of global efficiency after random attacks\n",
    "1. Pour chaque iteration (240), faire l’AUC (en prenant 30-100%) pour chaque patient; réduction de la matrice à 240X1X15\n",
    "2. Moyenner les valeurs ainsi obtenues pour chaque patient pour arriver à 15x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_data_path = '/Users/jk1/unige_onedrive/OneDrive - unige.ch/BCT/attacks240/attack_HC/rnd_attack_degrees_HC_05-12-2020 16-06v4.mat'\n",
    "st0_data_path = '/Users/jk1/unige_onedrive/OneDrive - unige.ch/BCT/attacks240/attack_ST01/rnd_attack_degrees_ST01_05-12-2020 17-46v4.mat'\n",
    "st1_data_path = '/Users/jk1/unige_onedrive/OneDrive - unige.ch/BCT/attacks240/attack_ST02/rnd_attack_degrees_ST02_05-12-2020 20-16v4.mat'\n",
    "st2_data_path = '/Users/jk1/unige_onedrive/OneDrive - unige.ch/BCT/attacks240/attack_ST03/rnd_attack_degrees_ST03_05-13-2020 18-19v4.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# global eff after attack\n",
    "outcome_var = 'GlobEff_bin_new'\n",
    "minimum_connectivity_threshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For this variable, data is available for the 8 remaining threshold bins [0.3-1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_data_mat = scipy.io.loadmat(hc_data_path)\n",
    "st0_data_mat = scipy.io.loadmat(st0_data_path)\n",
    "st1_data_mat = scipy.io.loadmat(st1_data_path)\n",
    "st2_data_mat = scipy.io.loadmat(st2_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_hc = len(hc_data_mat[outcome_var][0][0][0])\n",
    "n_st = len(st0_data_mat[outcome_var][0][0][0])\n",
    "n_bins = 11\n",
    "n_rois = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_mat_file(data_mat, n_subj, n_rois, outcome_var):\n",
    "    # parsing matlab matrix (roi, subj, bin) to obtain np array (subj, bin, roi)\n",
    "    glob_eff_random_attack = np.moveaxis(np.squeeze([[np.vstack(data_mat[outcome_var][0][0][roi_idx][subj_idx])\n",
    "                                 for subj_idx in range(n_subj)]\n",
    "                                    for roi_idx in range(n_rois)]), 0, -1)\n",
    "    return glob_eff_random_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_glob_eff_random_attack = parse_mat_file(hc_data_mat, n_hc, n_rois, outcome_var)\n",
    "st0_glob_eff_random_attack = parse_mat_file(st0_data_mat, n_st, n_rois, outcome_var)\n",
    "st1_glob_eff_random_attack = parse_mat_file(st1_data_mat, n_st, n_rois, outcome_var)\n",
    "st2_glob_eff_random_attack = parse_mat_file(st2_data_mat, n_st, n_rois, outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# correct for missing values - (pt1 TP1, pt5 Tp2, Pt13 (=pt17) TP3)\n",
    "st0_glob_eff_random_attack = np.insert(st0_glob_eff_random_attack, 0, np.full((n_bins, n_rois), np.NaN), axis=0)\n",
    "st1_glob_eff_random_attack = np.insert(st1_glob_eff_random_attack, 4, np.full((n_bins, n_rois), np.NaN), axis=0)\n",
    "st2_glob_eff_random_attack = np.insert(st2_glob_eff_random_attack, 12, np.full((n_bins, n_rois), np.NaN), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use auc only over predefined area of thresholds\n",
    "def custom_auc(values_over_thresholds):\n",
    "    # only analyse thresholds above minimum_connectivity_threshold\n",
    "    minimum_connectivity_threshold_index = int(minimum_connectivity_threshold*10)  # here thresholds start at bin0\n",
    "    connectivity_thresholds = np.arange(minimum_connectivity_threshold, 1.1, 0.1)\n",
    "\n",
    "    return auc(connectivity_thresholds,\n",
    "                values_over_thresholds[minimum_connectivity_threshold_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# take integral AUC over [0.3-1.0] interval\n",
    "hc_gEff_auc_random_attack = np.apply_along_axis(custom_auc, arr=hc_glob_eff_random_attack, axis=1)\n",
    "st0_gEff_auc_random_attack = np.apply_along_axis(custom_auc, arr=st0_glob_eff_random_attack, axis=1)\n",
    "st1_gEff_auc_random_attack = np.apply_along_axis(custom_auc, arr=st1_glob_eff_random_attack, axis=1)\n",
    "st2_gEff_auc_random_attack = np.apply_along_axis(custom_auc, arr=st2_glob_eff_random_attack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot mean AUC over number of attacked ROIs\n",
    "over_ROIs_df = pd.DataFrame({'n_rois': range(1,241),\n",
    "                            'HC': hc_gEff_auc_random_attack.mean(axis=0),\n",
    "                             'ST0': np.nanmean(st0_gEff_auc_random_attack, axis=0),\n",
    "                             'ST1': np.nanmean(st1_gEff_auc_random_attack, axis=0),\n",
    "                             'ST2': np.nanmean(st2_gEff_auc_random_attack, axis=0)})\n",
    "\n",
    "vertical_over_ROIs_df = over_ROIs_df.melt(id_vars=['n_rois'],\n",
    "                  value_vars=['HC', 'ST0', 'ST1', 'ST2'],\n",
    "                  var_name='group',\n",
    "                  value_name='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='n_rois', y='auc', hue='group',\n",
    "                data=vertical_over_ROIs_df[vertical_over_ROIs_df['group'].isin(['HC', 'ST2'])],\n",
    "                alpha=0.99, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "over_ROIs_df['delta_hc_st2'] = over_ROIs_df['HC'] - over_ROIs_df['ST2']\n",
    "\n",
    "ax = sns.scatterplot(x='n_rois', y='delta_hc_st2', hue='delta_hc_st2',\n",
    "                data=over_ROIs_df,\n",
    "                alpha=0.99, s=5)\n",
    "ax.set_title('Evolution of delta HC - ST2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_array_to_df(array, group_name):\n",
    "    df = pd.DataFrame(array.T)\n",
    "    df['n_rois_deleted'] = range(1,241)\n",
    "    df = df.melt(id_vars=['n_rois_deleted'],\n",
    "                      var_name='subject',\n",
    "                      value_name='gEff_auc')\n",
    "    df['group'] = group_name\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_subj_ROIs_df = pd.concat([prepare_array_to_df(hc_gEff_auc_random_attack, 'HC'),\n",
    "                              prepare_array_to_df(st0_gEff_auc_random_attack, 'ST0'),\n",
    "                              prepare_array_to_df(st1_gEff_auc_random_attack, 'ST1'),\n",
    "                              prepare_array_to_df(st2_gEff_auc_random_attack, 'ST2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='n_rois_deleted', y='gEff_auc', hue='group',\n",
    "                data=all_subj_ROIs_df[all_subj_ROIs_df['group'].isin(['HC', 'ST2'])],\n",
    "                alpha=0.5, s=0.1, y_jitter=0.5)\n",
    "\n",
    "ax.set_xlim(0,100)\n",
    "ax.set_ylim(0.15,0.5)\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Perform t-test at every n_rois_deleted to check when difference between HC and ST2 becomes insignificant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# limit number of deleted ROIs to 238, as there is no difference for the last two ROIs (resulting in pval NaN)\n",
    "max_deleted_ROIs = 238\n",
    "\n",
    "pvals_per_n_rois_deleted = np.array([stats.ttest_ind(\n",
    "    hc_gEff_auc_random_attack[:, n_rois_deleted],\n",
    "    st2_gEff_auc_random_attack[~np.isnan(st2_gEff_auc_random_attack).all(axis=1)][:, n_rois_deleted],\n",
    "    equal_var=False)[1] for n_rois_deleted in range(max_deleted_ROIs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(y=pvals_per_n_rois_deleted, x=range(1,max_deleted_ROIs+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, corrected_bh_fdr_pvals, _, _ = multitest.multipletests(pvals_per_n_rois_deleted, method='fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(y=corrected_bh_fdr_pvals, x=range(1,max_deleted_ROIs+1))\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(200, 240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Limits of global efficiency after repeated random attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_rep_data_path = '/Users/jk1/temp/stroke_resilience/output/repeated_random_attack/HC_rep100_rng_attack.mat'\n",
    "st2_rep_data_path = '/Users/jk1/temp/stroke_resilience/output/repeated_random_attack/ST3_rep100_rng_attack.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_rep_data_mat = scipy.io.loadmat(hc_rep_data_path)[outcome_var]\n",
    "st2_rep_data_mat = scipy.io.loadmat(st2_rep_data_path)[outcome_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_iterations = len(hc_rep_data_mat[0][0])\n",
    "n_rois = len(hc_rep_data_mat[0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_rep_mat_file(data_mat, n_rois):\n",
    "    # parsing matlab matrix (iteration, roi, subj, bin) to obtain np array (iteration, subj, bin, roi)\n",
    "    n_subj = len(data_mat[0][0][0][0][0][0])\n",
    "    glob_eff_rep_random_attack = np.squeeze([[[np.vstack(data_mat[0][0][iteration][0][0][roi_idx][subj_idx])\n",
    "                                 for subj_idx in range(n_subj)]\n",
    "                                    for roi_idx in range(n_rois)]\n",
    "                                        for iteration in range(n_iterations)])\n",
    "    return glob_eff_rep_random_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hc_rep_data = parse_rep_mat_file(hc_rep_data_mat, n_rois)\n",
    "st2_rep_data = parse_rep_mat_file(st2_rep_data_mat, n_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# take integral AUC over [0.3-1.0] interval\n",
    "hc_gEff_auc_rep_random_attack = np.apply_along_axis(custom_auc, arr=hc_rep_data, axis=-1)\n",
    "st2_gEff_auc_rep_random_attack = np.apply_along_axis(custom_auc, arr=st2_rep_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot mean AUC over number of attacked ROIs\n",
    "rep_over_ROIs_df = pd.DataFrame({'n_rois': range(1,241),\n",
    "                            'HC': hc_gEff_auc_rep_random_attack.mean(axis=(0, -1)),\n",
    "                             'ST2': np.nanmean(st2_gEff_auc_rep_random_attack, axis=(0, -1))})\n",
    "\n",
    "vertical_rep_over_ROIs_df = rep_over_ROIs_df.melt(id_vars='n_rois',\n",
    "                                                  value_vars=['HC', 'ST2'],\n",
    "                                                  var_name='group',\n",
    "                                                  value_name='gEff_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.scatterplot(x='n_rois', y='gEff_auc', hue='group',\n",
    "                data=vertical_rep_over_ROIs_df,\n",
    "                alpha=0.99, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rep_over_ROIs_df['delta_hc_st2'] = np.abs(rep_over_ROIs_df['HC'] - rep_over_ROIs_df['ST2'])\n",
    "\n",
    "ax = sns.scatterplot(x='n_rois', y='delta_hc_st2', hue='n_rois',\n",
    "                data=rep_over_ROIs_df,\n",
    "                alpha=0.99, s=5, legend=False)\n",
    "ax.set_xlabel('Number of deleted network nodes')\n",
    "ax.set_ylabel('Difference in global efficiency')\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# ax.set_title('Evolution of the difference in global efficiency between controls and subjects at timepoint 3')\n",
    "fig = ax.get_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "delta_st2_hc_over_rois_over_iterations = st2_gEff_auc_rep_random_attack.mean(axis=-1) - hc_gEff_auc_rep_random_attack.mean(axis=-1)\n",
    "delta_st2_hc_over_rois_over_iterations_df = pd.DataFrame(delta_st2_hc_over_rois_over_iterations)\n",
    "delta_st2_hc_over_rois_over_iterations_df['iteration'] = range(n_iterations)\n",
    "vert_delta_st2_hc_over_rois_over_iterations_df = delta_st2_hc_over_rois_over_iterations_df.melt(id_vars='iteration',\n",
    "                                                                                                value_vars=range(240),\n",
    "                                                                                                var_name='n_rois',\n",
    "                                                                                                value_name='delta_st2_hc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot mean difference in global efficiency between HC and ST2 for each number of deleted ROIs for each iteration\n",
    "ax = sns.scatterplot(x='n_rois', y='delta_st2_hc', hue='n_rois',\n",
    "                data=vert_delta_st2_hc_over_rois_over_iterations_df,\n",
    "                alpha=0.2, s=2, legend=False, y_jitter=0.5)\n",
    "ax.set_xlabel('Number of deleted network nodes')\n",
    "ax.set_ylabel('Difference in global efficiency')\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# ax.set_title('Evolution of the difference in global efficiency between controls and subjects at timepoint 3')\n",
    "fig = ax.get_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig('diff_eglob_hc_st2_repeated100_random_attack.tiff', format='tiff', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Perform t-test at every n_rois_deleted to check when difference between HC and ST2 becomes insignificant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# limit number of deleted ROIs to 238, as there is no difference for the last two ROIs (resulting in pval NaN)\n",
    "max_deleted_ROIs = 238\n",
    "\n",
    "pvals_per_rep_n_rois_deleted = np.array([[stats.ttest_ind(\n",
    "    hc_gEff_auc_rep_random_attack[iteration, n_rois_deleted],\n",
    "    st2_gEff_auc_rep_random_attack[iteration, n_rois_deleted],\n",
    "    equal_var=False)[1] for n_rois_deleted in range(max_deleted_ROIs)]\n",
    "                                     for iteration in range(n_iterations)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pvals_per_rep_n_rois_deleted_df = pd.DataFrame(pvals_per_rep_n_rois_deleted,\n",
    "                                               index=range(n_iterations),\n",
    "                                               columns=range(1,max_deleted_ROIs+1))\n",
    "pvals_per_rep_n_rois_deleted_df['n_rep_iter'] = range(n_iterations)\n",
    "pvals_per_rep_n_rois_deleted_df = pvals_per_rep_n_rois_deleted_df.melt(id_vars=['n_rep_iter'],\n",
    "                                     value_vars=range(1,max_deleted_ROIs+1),\n",
    "                                     var_name='n_rois_deleted',\n",
    "                                     value_name='pval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(y='pval', x='n_rois_deleted', hue='n_rois_deleted',\n",
    "                data=pvals_per_rep_n_rois_deleted_df,\n",
    "                alpha=0.99, s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corrected_bh_fdr_rep_pvals = multitest.multipletests(pvals_per_rep_n_rois_deleted.flatten(), method='fdr_bh')[1]\\\n",
    "                                        .reshape(pvals_per_rep_n_rois_deleted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corrected_bh_fdr_rep_pvals_df = pd.DataFrame(corrected_bh_fdr_rep_pvals,\n",
    "                                             index=range(n_iterations),\n",
    "                                             columns=range(1,max_deleted_ROIs+1))\n",
    "corrected_bh_fdr_rep_pvals_df['n_rep_iter'] = range(n_iterations)\n",
    "corrected_bh_fdr_rep_pvals_df = corrected_bh_fdr_rep_pvals_df.melt(id_vars=['n_rep_iter'],\n",
    "                                     value_vars=range(1,max_deleted_ROIs+1),\n",
    "                                     var_name='n_rois_deleted',\n",
    "                                     value_name='corrected_bh_fdr_pval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "\n",
    "ax = sns.scatterplot(y='corrected_bh_fdr_pval', x='n_rois_deleted', hue='n_rois_deleted',\n",
    "                data=corrected_bh_fdr_rep_pvals_df,\n",
    "                alpha=0.4, s=2, legend=False)\n",
    "\n",
    "# add line with median\n",
    "# sns.lineplot(x=range(1,max_deleted_ROIs+1), y=np.median(corrected_bh_fdr_rep_pvals, axis=0),\n",
    "#              color=sns.color_palette('inferno')[0],\n",
    "#              ax=ax, label='median', alpha=0.3)\n",
    "\n",
    "ax.set_xlabel('Number of deleted network nodes')\n",
    "ax.set_ylabel('p-value after FDR correction')\n",
    "ax.set_ylim(0.0, 0.2)\n",
    "# change y tick frequency to 0.05\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "\n",
    "# Hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig = ax.get_figure()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig('limits_of_resilience_after_repeated100_random_attack.tiff', format='tiff', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
